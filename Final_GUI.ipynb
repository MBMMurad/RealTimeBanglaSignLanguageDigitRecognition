{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(img):\n",
    "    #img1 = rgb2gray(img)\n",
    "    img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = img\n",
    "    #blur = cv2.GaussianBlur(img1,(3,3),0)\n",
    "    #ret,thresh1 = cv2.threshold(img1,225,255,cv2.THRESH_BINARY_INV)\n",
    "    thresh1 = cv2.adaptiveThreshold(img1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,133,5)\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh1, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    b,g,r = cv2.split(img2)\n",
    "    for i in range(closing.shape[0]):\n",
    "      for j in range(closing.shape[1]):\n",
    "        if(closing[i,j])==0:\n",
    "          b[i,j] = 0\n",
    "          g[i,j] = 0\n",
    "          r[i,j] = 0\n",
    "\n",
    "    newimg = cv2.merge((b,g,r))\n",
    "    newimg=cv2.cvtColor(newimg, cv2.COLOR_BGR2GRAY)\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {0:'Zero',1:'One',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras.models.load_model(\"Model_final.h5\")\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "ROI_top = 0\n",
    "ROI_bottom = 250\n",
    "ROI_right =0\n",
    "ROI_left =300\n",
    "def inp(i):\n",
    "    i=np.array(i)\n",
    "    i=i[...,np.newaxis]\n",
    "    l=[]\n",
    "    l.append(i)\n",
    "    l=np.array(l)\n",
    "    return l\n",
    "\n",
    "def remove_background(img):\n",
    "    #img1 = rgb2gray(img)\n",
    "    x=np.array(img)\n",
    "    if x.ndim==3:\n",
    "        img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img1=img\n",
    "    img2 = img\n",
    "    #blur = cv2.GaussianBlur(img1,(3,3),0)\n",
    "    #ret,thresh1 = cv2.threshold(img1,225,255,cv2.THRESH_BINARY_INV)\n",
    "    thresh1 = cv2.adaptiveThreshold(img1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,133,5)\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh1, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    b,g,r = cv2.split(img2)\n",
    "    for i in range(closing.shape[0]):\n",
    "      for j in range(closing.shape[1]):\n",
    "        if(closing[i,j])==0:\n",
    "          b[i,j] = 0\n",
    "          g[i,j] = 0\n",
    "          r[i,j] = 0\n",
    "\n",
    "    newimg = cv2.merge((b,g,r))\n",
    "    newimg=cv2.cvtColor(newimg, cv2.COLOR_BGR2GRAY)\n",
    "    return newimg\n",
    "\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # filpping the frame to prevent inverted image of captured frame...\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    #gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame=roi\n",
    "    #gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    \n",
    "    gray_frame=remove_background(gray_frame)\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "    #cv2.drawContours(frame_copy, [(ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "    cv2.imshow(\"Thesholded Hand Image\", gray_frame)\n",
    "            \n",
    "    thresholded = cv2.resize(gray_frame, (160, 120))\n",
    "    thresholded=thresholded/255\n",
    "    x=inp(thresholded)\n",
    "    #thresholded = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "    #thresholded = np.reshape(thresholded, (1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "    pred = model.predict(x)\n",
    "    cv2.putText(frame_copy, word_dict[np.argmax(pred)], (170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    #cv2.putText(frame_copy, \"DataFlair hand sign recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Languag Digit Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
